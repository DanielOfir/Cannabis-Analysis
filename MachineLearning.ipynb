{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('python@3.9')"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  },
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing, linear_model, model_selection, metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name, label_column,no_hybrid=False):\n",
    "    \n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df.loc[:,~df.columns.str.match(\"Unnamed\")]\n",
    "\n",
    "    cols = ['Top Terpene','Feeling_1','Feeling_2','Feeling_3','Feeling_4','Feeling_5','Negative_1','Negative_2','Negative_3','Negative_4','Negative_5','Helps with_1','Helps with_2','Helps with_3','Helps with_4','Helps with_5','Flavor_1','Flavor_2','Flavor_3']\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    df = df.drop(columns=['Strain Name'])\n",
    "\n",
    "    if no_hybrid == True:\n",
    "        df = df[df['Type'] != 'Hybrid']\n",
    "\n",
    "    X = df.loc[:,df.columns != label_column].copy()\n",
    "    y = df[label_column]\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_and_test(X, y, test_ratio, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_ratio,random_state=rand_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_features(X_train, scale_type):\n",
    "\n",
    "    if scale_type == 'minmax':\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    elif scale_type == 'standard':\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)   \n",
    "\n",
    "    return scaler, X_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_test_features(X_test, scaler):\n",
    "\n",
    "    scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "\n",
    "    classification_model = LogisticRegression(max_iter=9000).fit(X_train,y_train)\n",
    "\n",
    "    return classification_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(classifier, X_test, y_test):\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_test,y_predicted):\n",
    "\n",
    "    evaluate_value = metrics.f1_score(y_test,y_predicted,average='micro')\n",
    "\n",
    "    return evaluate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No sclaing (F1 Score): 0.6483870967741936\nStandard scaling (F1 Score): 0.6435483870967742\nMinMax scaling (F1 Score): 0.6435483870967742\n"
     ]
    }
   ],
   "source": [
    "## Train and Predict - All data ##\n",
    "\n",
    "file_name = 'CSVs/clean_df(post EDA).csv'\n",
    "category_col_name = 'Type'\n",
    "\n",
    "X, y = load_dataset(file_name, category_col_name)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(X, y, 0.3, 14)\n",
    "\n",
    "\n",
    "standard_scaler, X_train_standard_scaled = scale_features(X_train, 'standard')\n",
    "minmax_scaler, X_train_minmax_scaled = scale_features(X_train, 'minmax')\n",
    "X_test_standard_scaled = scale_test_features(X_test, standard_scaler)\n",
    "X_test_minmax_scaled = scale_test_features(X_test, minmax_scaler)\n",
    "\n",
    "classification_model = train_classifier(X_train, y_train)\n",
    "classification_standard_model = train_classifier(X_train_standard_scaled, y_train)\n",
    "classification_minmax_model = train_classifier(X_train_minmax_scaled, y_train)\n",
    "\n",
    "df_res = predict(classification_model, X_test, y_test)\n",
    "df_standard_res = predict(classification_standard_model, X_test_standard_scaled, y_test)\n",
    "df_minmax_res = predict(classification_minmax_model, X_test_minmax_scaled, y_test)\n",
    "\n",
    "y_pred_1st= pd.Series(df_res,index=X_test.index)\n",
    "eval_res_1st = evaluate_performance(y_test, y_pred_1st)\n",
    "\n",
    "y_pred_1st_standard= pd.Series(df_standard_res,index=X_test.index)\n",
    "eval_res_1st_standard = evaluate_performance(y_test, y_pred_1st_standard)\n",
    "\n",
    "y_pred_1st_minmax= pd.Series(df_minmax_res,index=X_test.index)\n",
    "eval_res_1st_minmax = evaluate_performance(y_test, y_pred_1st_minmax)\n",
    "\n",
    "\n",
    "print(f\"No sclaing (F1 Score): {eval_res_1st}\")\n",
    "print(f\"Standard scaling (F1 Score): {eval_res_1st_standard}\")\n",
    "print(f\"MinMax scaling (F1 Score): {eval_res_1st_minmax}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No Hybrid - No sclaing (F1 Score): 0.8469750889679716\nNo Hybrid - Standard scaling (F1 Score): 0.8469750889679716\nNo Hybrid - MinMax scaling (F1 Score): 0.8362989323843416\n"
     ]
    }
   ],
   "source": [
    "## Train and Predict - No Hybrid ##\n",
    "\n",
    "file_name = 'CSVs/clean_df(post EDA).csv'\n",
    "category_col_name = 'Type'\n",
    "\n",
    "X, y = load_dataset(file_name, category_col_name,no_hybrid=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(X, y, 0.3, 14)\n",
    "\n",
    "\n",
    "standard_scaler, X_train_standard_scaled = scale_features(X_train, 'standard')\n",
    "minmax_scaler, X_train_minmax_scaled = scale_features(X_train, 'minmax')\n",
    "X_test_standard_scaled = scale_test_features(X_test, standard_scaler)\n",
    "X_test_minmax_scaled = scale_test_features(X_test, minmax_scaler)\n",
    "\n",
    "classification_model = train_classifier(X_train, y_train)\n",
    "classification_standard_model = train_classifier(X_train_standard_scaled, y_train)\n",
    "classification_minmax_model = train_classifier(X_train_minmax_scaled, y_train)\n",
    "\n",
    "df_res = predict(classification_model, X_test, y_test)\n",
    "df_standard_res = predict(classification_standard_model, X_test_standard_scaled, y_test)\n",
    "df_minmax_res = predict(classification_minmax_model, X_test_minmax_scaled, y_test)\n",
    "\n",
    "y_pred_1st= pd.Series(df_res,index=X_test.index)\n",
    "eval_res_1st = evaluate_performance(y_test, y_pred_1st)\n",
    "\n",
    "y_pred_1st_standard= pd.Series(df_standard_res,index=X_test.index)\n",
    "eval_res_1st_standard = evaluate_performance(y_test, y_pred_1st_standard)\n",
    "\n",
    "y_pred_1st_minmax= pd.Series(df_minmax_res,index=X_test.index)\n",
    "eval_res_1st_minmax = evaluate_performance(y_test, y_pred_1st_minmax)\n",
    "\n",
    "\n",
    "print(f\"No Hybrid - No sclaing (F1 Score): {eval_res_1st}\")\n",
    "print(f\"No Hybrid - Standard scaling (F1 Score): {eval_res_1st_standard}\")\n",
    "print(f\"No Hybrid - MinMax scaling (F1 Score): {eval_res_1st_minmax}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}