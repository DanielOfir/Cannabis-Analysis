{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ## To get htmls\n",
    "import re ## to find\n",
    "import ast\n",
    "import bs4\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import scipy as scipy\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "import matplotlib.pyplot as plt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import threading\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feelings(soup):\n",
    "\n",
    "    ### Get feelings\n",
    "    try:\n",
    "        feelings = {'Feelings':[],'Negatives':[],'Helps with':[]}\n",
    "\n",
    "        all_feelings = soup.find_all('div',{\"role\":'tabpanel'})\n",
    "        site_effects = soup.find_all('li',{\"role\":'tab'})\n",
    "\n",
    "        if len([i.text for i in site_effects]) < 3:\n",
    "            if \"Negatives\" not in [i.text for i in site_effects]:\n",
    "                if \"Feelings\" in [i.text for i in site_effects]:\n",
    "                    for i, child in enumerate(all_feelings,0):\n",
    "                        curr = child.findAll('div',recursive=False)\n",
    "                        \n",
    "                        if i == 0:           \n",
    "                            for item in curr:\n",
    "                                match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                                feelings['Feelings'].append(match)\n",
    "                        if i == 1:\n",
    "                            for item in curr:\n",
    "                                match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                                feelings['Helps with'].append(match)\n",
    "                \n",
    "                else: ## If both Negatives and Feelings don't exist - Fill only the 'Helps with'\n",
    "                    for i, child in enumerate(all_feelings,0):\n",
    "                        curr = child.findAll('div',recursive=False)\n",
    "                        for item in curr:\n",
    "                            match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                            feelings['Helps with'].append(match)\n",
    "            \n",
    "            if \"Helps with\" not in [i.text for i in site_effects] and len(feelings['Feelings']) == 0 and len(feelings['Negatives']) == 0:\n",
    "\n",
    "                for i, child in enumerate(all_feelings,0):\n",
    "                    curr = child.findAll('div',recursive=False)\n",
    "                    \n",
    "                    if i == 0:           \n",
    "                        for item in curr:\n",
    "                            match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                            feelings['Feelings'].append(match)\n",
    "                    if i == 1:\n",
    "                        for item in curr:\n",
    "                            match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                            feelings['Negatives'].append(match)\n",
    "\n",
    "            if \"Feelings\" not in [i.text for i in site_effects] and len(feelings['Negatives']) == 0 and len(feelings['Helps with']) == 0:\n",
    "\n",
    "                for i, child in enumerate(all_feelings,0):\n",
    "                    curr = child.findAll('div',recursive=False)\n",
    "                    \n",
    "                    if i == 0:           \n",
    "                        for item in curr:\n",
    "                            match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                            feelings['Negatives'].append(match)\n",
    "                    if i == 1:\n",
    "                        for item in curr:\n",
    "                            match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                            feelings['Helps with'].append(match)\n",
    "        \n",
    "        else:\n",
    "            for i, child in enumerate(all_feelings,0):\n",
    "                curr = child.findAll('div',recursive=False)\n",
    "                \n",
    "                if i == 0:           \n",
    "                    for item in curr:\n",
    "                        match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                        feelings['Feelings'].append(match)\n",
    "                if i == 1:\n",
    "                    for item in curr:\n",
    "                        match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                        feelings['Negatives'].append(match)\n",
    "                if i == 2:\n",
    "                    for item in curr:\n",
    "                        match = re.findall(\"[A-Z a-z]+\", item.text)[0]\n",
    "                        feelings['Helps with'].append(match)\n",
    "\n",
    "\n",
    "        if len(feelings['Feelings']) < 5:\n",
    "            for i in range(5-len(feelings['Feelings'])):\n",
    "                feelings['Feelings'].append(None) \n",
    "\n",
    "        if len(feelings['Negatives']) < 5:\n",
    "            for i in range(5-len(feelings['Negatives'])):\n",
    "                feelings['Negatives'].append(None) \n",
    "\n",
    "        if len(feelings['Helps with']) < 5:\n",
    "            for i in range(5-len(feelings['Helps with'])):\n",
    "                feelings['Helps with'].append(None) \n",
    "\n",
    "        return feelings\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scrape data from html\n",
    "\n",
    "def get_strainType(soup):\n",
    "\n",
    "    ## Strain type - Sativa, Indica or Hybrid\n",
    "    try:\n",
    "        strain_type = soup.find_all('span',class_='jsx-1167018388 text-xs bg-leafly-white py-sm px-sm rounded')\n",
    "        if len(strain_type) > 0:\n",
    "            strain_type = strain_type[0].text\n",
    "        else:\n",
    "            strain_type = None\n",
    "\n",
    "        return strain_type\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "def get_terpene(soup):\n",
    "\n",
    "    ## Top terpene\n",
    "    try:\n",
    "        top_terpene = soup.find_all('span',class_='jsx-1167018388 ml-xs')\n",
    "        if len(top_terpene) > 0:\n",
    "            top_terpene = top_terpene[0].text\n",
    "        else:\n",
    "            top_terpene = None\n",
    "\n",
    "        return top_terpene\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "def get_cannabinoid(soup):\n",
    "    \n",
    "    ## Cannabinoids\n",
    "    try:\n",
    "        cannabinoids = {\"THC\": None, \"CBD\": None, \"CBG\":None}\n",
    "        cannabinoids_list = soup.find_all('span',class_='jsx-1167018388 text-xs py-sm px-sm ml-sm rounded')\n",
    "        if len(cannabinoids_list) > 0:\n",
    "            for i in soup.find_all('span',class_='jsx-1167018388 text-xs py-sm px-sm ml-sm rounded'):\n",
    "                if i.text.startswith(\"THC\"):\n",
    "                    cannabinoids['THC'] = i.text.split()[1]\n",
    "\n",
    "                elif i.text.startswith(\"CBD\"):\n",
    "                    cannabinoids['CBD'] = i.text.split()[1]\n",
    "\n",
    "                elif i.text.startswith(\"CBG\"):\n",
    "                    cannabinoids['CBG'] = i.text.split()[1]\n",
    "        else:\n",
    "            cannabinoids['THC'] = None\n",
    "            cannabinoids['CBD'] = None\n",
    "            cannabinoids['CBG'] = None\n",
    "\n",
    "        return cannabinoids\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "def get_rating(soup):\n",
    "\n",
    "    ## Rating \n",
    "    try:\n",
    "        rating = soup.find_all('span',class_='pr-xs')\n",
    "        if len(rating) > 0:\n",
    "            rating = rating[0].text\n",
    "        else:\n",
    "            rating = None\n",
    "\n",
    "        return rating\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "def get_ratingNum(soup):\n",
    "\n",
    "    ## Number of rating users\n",
    "    try:\n",
    "        rating_num = soup.find_all('span',class_='pl-xs')\n",
    "        if len(rating_num) > 0:\n",
    "            rating_users = re.findall(\"[0-9]+\", rating_num[0].text)[0]\n",
    "        else:\n",
    "            rating_users = None\n",
    "\n",
    "        return rating_users\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "def get_name(soup):\n",
    "    try:\n",
    "        name = soup.find('h1',{'itemprop':\"name\"})\n",
    "        \n",
    "        if len(name)> 0:\n",
    "            name = name.text\n",
    "        else:\n",
    "            name = None\n",
    "\n",
    "        return name\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linage(soup):\n",
    "\n",
    "    left_parent = soup.find_all('div',class_='lineage__left-parent')\n",
    "    right_parent = soup.find_all('div',class_='lineage__right-parent')\n",
    "    left_child = soup.find_all('div',class_='lineage__left-child--two-parents')\n",
    "    right_child = soup.find_all('div',class_='lineage__right-child--two-parents')\n",
    "\n",
    "    ## Handle parents (might be single parent)\n",
    "    if len(left_parent) == 0 or len(right_parent) == 0:\n",
    "        parent = soup.find_all('div','lineage__center-parent')\n",
    "        if len(parent) > 0:\n",
    "            left_parent = parent[0].text.split(\"parent\")[0]\n",
    "            right_parent = 'N/A'\n",
    "        else:\n",
    "            left_parent = None\n",
    "            right_parent = None\n",
    "    else:\n",
    "        left_parent = left_parent[0].text.split(\"parent\")[0]\n",
    "        right_parent = right_parent[0].text.split(\"parent\")[0]\n",
    "\n",
    "    ## Handle left child (might be child of strain with single parent)\n",
    "    if len(left_child) == 0:\n",
    "        left_child = soup.find_all('div',class_='lineage__left-child--single-parent')\n",
    "        if len(left_child) > 0:\n",
    "            left_child = left_child[0].text.split(\"child\")[0]\n",
    "        else:\n",
    "            left_child = None\n",
    "    else:\n",
    "        left_child = left_child[0].text.split(\"child\")[0]\n",
    "\n",
    "    ## Handle left child (might be child of strain with single parent)\n",
    "    if len(right_child) == 0:\n",
    "        right_child = soup.find_all('div',class_='lineage__right-child--single-parent')\n",
    "        if len(right_child) > 0:\n",
    "            right_child = right_child[0].text.split(\"child\")[0]\n",
    "        else:\n",
    "            right_child = None\n",
    "    else:\n",
    "        right_child = right_child[0].text.split(\"child\")[0]\n",
    "\n",
    "    return left_parent,right_parent,left_child,right_child\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting all the crawling data\n",
    "\n",
    "def scrape_data(soup):\n",
    "    try:\n",
    "        name = get_name(soup)\n",
    "        feelings = get_feelings(soup)\n",
    "        strain_type =  get_strainType(soup)\n",
    "        cannabinoids =  get_cannabinoid(soup)\n",
    "        rating = get_rating(soup)\n",
    "        rating_users = get_ratingNum(soup)\n",
    "        left_parent,right_parent,left_child,right_child = get_linage(soup)\n",
    "        top_terpene = get_terpene(soup)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    return name,feelings, strain_type, cannabinoids, rating, rating_users, left_parent,right_parent,left_child,right_child,top_terpene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Selenium driver\n",
    "def get_driver():\n",
    "    \n",
    "  driver = getattr(threadLocal, 'driver', None)\n",
    "  if driver is None:\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "    chromeOptions.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=chromeOptions)\n",
    "    setattr(threadLocal, 'driver', driver)\n",
    "  return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for the thread to run\n",
    "\n",
    "def get_strain_data(url):\n",
    "\n",
    "    full_url = 'https://www.leafly.com' + url\n",
    "    driver = get_driver()\n",
    "    driver.get(full_url)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    try:\n",
    "        name, feelings, strain_type, cannabinoids, rating, rating_users, left_parent,right_parent,left_child,right_child,top_terpene = scrape_data(soup)\n",
    "        return name, feelings, strain_type, cannabinoids, rating, rating_users, left_parent,right_parent,left_child,right_child,top_terpene\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strain_names(page_number):\n",
    "\n",
    "    strains = set()\n",
    "\n",
    "    url = f'https://www.leafly.com/strains?page={page_number}'\n",
    "    driver = get_driver()\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')    \n",
    "    try: \n",
    "        for a in soup.find_all('a',href=True):\n",
    "            if a['href'].startswith(\"/strains/\") and not a['href'].startswith(\"/strains/lists\"):\n",
    "                strains.add(a['href'])\n",
    "    \n",
    "        return strains\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_thread(mode,strains=None):\n",
    "    \n",
    "    if mode == 'Strain Data':\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        with ThreadPool(10) as pool:\n",
    "            for name, feelings, strain_type, cannabinoids, rating, rating_users, left_parent,right_parent,left_child,right_child,top_terpene in pool.map(get_strain_data, strains):\n",
    "\n",
    "                data.append({'Strain Name':name, \n",
    "                'Feelings': feelings, \n",
    "                'Type': strain_type, \n",
    "                'Cannabinoids': cannabinoids, \n",
    "                'Rating': rating, \n",
    "                'Rating Users': rating_users,\n",
    "                'Left Parent': left_parent,\n",
    "                'Right Parent': right_parent,\n",
    "                'Left Child': left_child,\n",
    "                'Right Child': right_child,\n",
    "                'Top Terpene': top_terpene})\n",
    "        \n",
    "        return data\n",
    "\n",
    "    elif mode == 'Strain Names':\n",
    "\n",
    "        strain_names = []\n",
    "\n",
    "        url = 'https://www.leafly.com/strains'\n",
    "        driver = get_driver()\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "        pages = int(str(soup.find_all('span',class_=\"mx-lg md:mx-xxl\")[0]).split()[-1].split(\"<\")[0])\n",
    "        max_pages = range(1,pages+1)\n",
    "\n",
    "        with ThreadPool(10) as pool:\n",
    "            for result in pool.map(get_strain_names,max_pages):\n",
    "                strain_names.append(result)\n",
    "\n",
    "\n",
    "        return strain_names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadLocal = threading.local()\n",
    "start = time.perf_counter()\n",
    "strain_names = run_thread('Strain Names')\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished in {round((finish-start)/60,2)} minutes')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_names_list = list(set().union(*strain_names)) ## Convert list of sets to list of single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strain_list.txt','w') as f:\n",
    "    json.dump(strain_names_list,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('strain_list.txt', 'r') as filehandle:\n",
    "    strains = json.load(filehandle)\n",
    "\n",
    "\n",
    "print(len(strains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "<ipython-input-6-928dbbcef8f3>:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=chromeOptions)\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "Driver [/Users/daniel.ofir/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "Finished in 31.45 minutes\n"
     ]
    }
   ],
   "source": [
    "with open('strain_list.txt', 'r') as filehandle:\n",
    "    strains = json.load(filehandle)\n",
    "\n",
    "threadLocal = threading.local()\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "data = run_thread('Strain Data',strains) ## Takes around 25 minutes\n",
    "\n",
    "finish = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {round((finish-start)/60,2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Dataframe\n",
    "\n",
    "keys = list(data[0].keys())\n",
    "df = pd.DataFrame(data,columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to csv\n",
    "\n",
    "# df.head()\n",
    "\n",
    "df.to_csv('canna_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}